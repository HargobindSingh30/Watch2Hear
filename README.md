# Watch2Hear
Developed Watch2Hear, a reliable deep learning model that can read lips from audioless video files and output text for the same using Python, OpenCV, imageio, and Tensorflow that can act as a communication aid for deaf people.

# Sample Video

![image](https://github.com/user-attachments/assets/64752597-7ca5-4984-8a18-f2828fef864f)

Extraction Area:

![image](https://github.com/user-attachments/assets/6079e30c-b966-4037-b941-2770aea2cfd2)


Prediction by model after reading Lips:
![image](https://github.com/user-attachments/assets/bc3f7345-30ec-4395-8c69-d381cffafaf7)
